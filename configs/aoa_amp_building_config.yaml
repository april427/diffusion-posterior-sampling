# Configuration for training diffusion model on AoA/Amplitude data with buildings
# This uses the ray tracing approach with fixed buildings and strongest 3 paths

# Model architecture settings
image_size: 128         # Spatial resolution (100x100 to match map size)
num_channels: 64        # Base number of channels
num_res_blocks: 2       # Number of residual blocks per resolution
channel_mult: "1,2,2,4"  # Channel multipliers for different resolutions
attention_resolutions: "25,50"  # Attention at 1/4 and 1/2 resolution
num_heads: 4            # Number of attention heads
num_head_channels: 16   # Channels per attention head
use_scale_shift_norm: True
dropout: 0.1
resblock_updown: True
use_checkpoint: False
use_fp16: False
use_new_attention_order: False
model_path: checkpoints/aoa_amp_building/checkpoint_step_40000.pt  # set to desired checkpoint

# Data-specific settings
class_cond: False       # No class conditioning
learn_sigma: True       # Learn noise variance

# Channel configuration (6 channels: 3 AoA + 3 Amplitude for strongest paths)
data_channels: 6        # AoA + Amplitude for 3 strongest paths

# Training settings
batch_size: 8           # Smaller batch size due to larger images and more channels
learning_rate: 0.0001
num_epochs: 500         # Reduced epochs for initial training
save_interval: 2000     # Save checkpoint every N steps
epoch_save_interval: 10 # Save full checkpoint/samples every N epochs
log_interval: 50        # Log every N steps

# Dataset settings
dataset:
  name: "aoa_amp_building"
  root: "./data/building_training_randomized"
  map_size: [128, 128]
  grid_spacing: 1.0     # UE grid spacing (creates 100x100 grid)
  bs_grid_spacing: 64.0  # BS every 5 meters
 
 # Randomized building configurations
  num_building_sets: 3
  building_distribution: [1, 1, 1]  # 40 configs each for 1, 2, 3 buildings
  building_size_range: [[15, 35], [10, 25]]  # [[min_width, max_width], [min_height, max_height]]
  min_building_distance: 5.0
  seed: 42

  use_existing_data: True  # Use existing data if available
  normalize_data: True
  
# GPU optimization parameters
  device: 'auto'  # 'cuda', 'cpu', or 'auto'
  use_gpu_processing: True
  batch_size: 32
  num_workers: 8  # Adjust based on your CPU cores
  pin_memory: True
  prefetch_factor: 2

# DataLoader settings
dataloader:
  batch_size: 8
  num_workers: 2        # Reduced workers due to larger data
  shuffle: True
